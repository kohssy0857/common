{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第５章　演習２\n",
    "## 問題１\n",
    "### （１）下記のプログラムを実行してください。\n",
    "### （２）予測・比較・学習部分の処理、それに伴う関数 vect_mat_mul の修正をそれぞれコメントに従って実装してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👇リスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.061325 0.0970425 -0.30546\n",
      "0.1017 0.20013 0.00023999999999999887\n",
      "-0.07352500000000001 1.2943775 0.08962\n"
     ]
    }
   ],
   "source": [
    "# NumPyのインポート、別名 np\n",
    "import numpy as np\n",
    "\n",
    "# 加重和（内積）を求める関数 w_sum の定義\n",
    "def w_sum(a, b):\n",
    "    # ２つの引数のリストの長さが等しいとき以下を実行する\n",
    "    assert(len(a) == len(b))\n",
    "    # 加重和の初期化\n",
    "    output = 0\n",
    "    # 加重和を求める\n",
    "    # 引数のリストの長さ分繰り返す\n",
    "    for i in range(len(a)):\n",
    "        # リストの要素同士を掛けて合計を求める\n",
    "        output += (a[i] * b[i])\n",
    "    # 加重和を返す\n",
    "    return output\n",
    "\n",
    "# ベクトルと行列のかけ算を求める関数 vect_mat_mul の定義\n",
    "def vect_mat_mul(vect, matrix):\n",
    "    # ベクトルと行列の行リストの長さが等しいとき以下を実行する\n",
    "    assert(len(vect) == len(matrix))\n",
    "    # 加重和リストの初期化\n",
    "    output = [0, 0, 0]\n",
    "    # ベクトルの長さ（＝行列の行リストの長さ）分繰り返す\n",
    "    for i in range(len(vect)):\n",
    "        # ベクトルの行列の各行との加重和を求める\n",
    "        output[i] = w_sum(vect, matrix[i])\n",
    "    # 加重和のリストを返す\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "# ２つのリストの要素間を総なめして要素ごとのかけ算をして\n",
    "# その結果を行列に格納する関数 outer_prod の定義\n",
    "def outer_prod(a, b):\n",
    "    # a 行 b 列のゼロ行列を生成する\n",
    "    out = np.zeros((len(a), len(b)))\n",
    "    # a 行 b 列の行列にリスト a とリスト b の\n",
    "    # 要素を総なめしたかけ算を行い、行列に格納する\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(b)):\n",
    "            out[i][j] = a[i] * b[j]\n",
    "    # 要素間のかけ算の結果を保存した行列を返す\n",
    "    return out\n",
    "\n",
    "# 予測値を求める関数 nuural_network の定義\n",
    "def neural_network(input, weights):\n",
    "    # ベクトルと行列の加重和を求める\n",
    "    pred = vect_mat_mul(input, weights)\n",
    "    # 予測値のリストを返す\n",
    "    return pred\n",
    "\n",
    "# 重みの初期化\n",
    "            #toes %win #fans\n",
    "weights = [ [0.1, 0.1, -0.3], # けが？\n",
    "            [0.1, 0.2, 0.0],  # 勝った？\n",
    "            [0.0, 1.3, 0.1] ] # 悲しい？\n",
    "\n",
    "# シーズン４試合の足指の数の平均\n",
    "toes  = [8.5, 9.5, 9.9, 9.0]\n",
    "# シーズン４試合の勝率\n",
    "wlrec = [0.65,0.8, 0.8, 0.9]\n",
    "# シーズン４試合のファンの数\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "# シーズン４試合のけが度\n",
    "hurt  = [0.1, 0.0, 0.0, 0.1]\n",
    "# シーズン４試合の勝ち負け\n",
    "win   = [  1,   1,   0,   1]\n",
    "# シーズン４試合の悲しみ度\n",
    "sad   = [0.1, 0.0, 0.1, 0.2]\n",
    "# アルファの初期化\n",
    "alpha = 0.01\n",
    "# 入力データの設定（シーズン第１試合の [足指の数の平均値, 勝率, ファンの数]\n",
    "input = [toes[0], wlrec[0], nfans[0]]\n",
    "# シーズン第１試合の結果の設定（[けが度, 勝ち負け, 悲しみ度]\n",
    "true  = [hurt[0], win[0], sad[0]]\n",
    "\n",
    "# 勾配降下法による学習\n",
    "\n",
    "# 予測値を求める\n",
    "pred = neural_network(input,weights)\n",
    "\n",
    "# 誤差の初期化\n",
    "error = [0, 0, 0]\n",
    "# デルタの初期化\n",
    "delta = [0, 0, 0]\n",
    "\n",
    "# 予測値の数分繰り返す\n",
    "for i in range(len(true)):\n",
    "    # 誤差を求める\n",
    "    error[i] = (pred[i] - true[i]) ** 2\n",
    "    # デルタを求める\n",
    "    delta[i] = pred[i] - true[i]\n",
    "\n",
    "# 重みの微調整量を求め行列に格納する\n",
    "weight_deltas = outer_prod(delta, input)\n",
    "\n",
    "# 重み行列を更新する\n",
    "for i in range(len(weights)):\n",
    "    for j in range(len(weights[0])):\n",
    "        weights[i][j] -= alpha * weight_deltas[i][j]\n",
    "\n",
    "# 更新された重み行列を表示する\n",
    "for i in range(len(weights)):\n",
    "    print('{} {} {}'.format(weights[i][0], weights[i][1], weights[i][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👇未完成リスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "予測値 = [0.555, 0.9800000000000001, 0.9650000000000001]\n",
      "更新された重み\n",
      "0.06132500 : 0.09704250 : -0.30546000\n",
      "0.10170000 : 0.20013000 : 0.00024000\n",
      "-0.07352500 : 1.29437750 : 0.08962000\n"
     ]
    }
   ],
   "source": [
    "# NumPyのインポート、別名 np\n",
    "import numpy as np\n",
    "\n",
    "# 加重和（内積）を求める関数 w_sum の定義\n",
    "def w_sum(a, b):\n",
    "    # ２つの引数のリストの長さが等しいとき以下を実行する\n",
    "    assert(len(a) == len(b))\n",
    "    # 加重和の初期化\n",
    "    output = 0\n",
    "    # 加重和を求める\n",
    "    # 引数のリストの長さ分繰り返す\n",
    "    for i in range(len(a)):\n",
    "        # リストの要素同士を掛けて合計を求める\n",
    "        output += (a[i] * b[i])\n",
    "    # 加重和を返す\n",
    "    return output\n",
    "\n",
    "# ベクトルと行列のかけ算を求める関数 vect_mat_mul の定義\n",
    "\n",
    "    # ベクトルと行列の行リストの長さが等しいとき以下を実行する\n",
    "    \n",
    "    # 加重和リストの初期化\n",
    "    \n",
    "    # ベクトルの長さ（＝行列の行リストの長さ）分繰り返す\n",
    "    \n",
    "        # ベクトルの行列の各行との加重和を求めて out に追加する\n",
    "        \n",
    "    # 加重和のリストを返す\n",
    "    \n",
    "\n",
    "# ２つのリストの要素間を総なめして要素ごとのかけ算をして\n",
    "# その結果を行列に格納する関数 outer_prod の定義\n",
    "def outer_prod(a, b):\n",
    "    # a 行 b 列のゼロ行列を生成する\n",
    "    out = np.zeros((len(a), len(b)))\n",
    "    # a 行 b 列の行列にリスト a とリスト b の\n",
    "    # 要素を総なめしたかけ算を行い、行列に格納する\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(b)):\n",
    "            out[i][j] = a[i] * b[j]\n",
    "    # 要素間のかけ算の結果を保存した行列を返す\n",
    "    return out\n",
    "\n",
    "# 予測値を求める関数 nuural_network の定義\n",
    "def neural_network(input, weights):\n",
    "    # ベクトルと行列の加重和を求める\n",
    "    pred = vect_mat_mul(input, weights)\n",
    "    # 予測値のリストを返す\n",
    "    return pred\n",
    "\n",
    "# 学習関数 grad_descent_learn(input, truth, pred, weights, alpha) の定義\n",
    "'''\n",
    "関数名：grad_descent_learn\n",
    "引数：\n",
    "    input：入力値リスト\n",
    "    truth：目的値リスト\n",
    "    pred：予測値リスト\n",
    "    weights：重みリスト\n",
    "    alpha：重み再微調整値\n",
    "処理：勾配降下法に基づき重みを修正する\n",
    "戻り値：修正された重みリスト\n",
    "'''\n",
    "\n",
    "    # デルタの初期化\n",
    "    \n",
    "    # 予測値の数分繰り返す\n",
    "    \n",
    "        # デルタを求めてデルタのリストに追加する\n",
    "        \n",
    "    # 重みの微調整量を求め行列に格納する\n",
    "    \n",
    "    # 重み行列を更新する（２重ループ）\n",
    "    \n",
    "    \n",
    "\n",
    "    # 重み行列を返す\n",
    "    \n",
    "\n",
    "\n",
    "# 重みの初期化\n",
    "            #toes %win #fans\n",
    "weights = [ [0.1, 0.1, -0.3], # けが？\n",
    "            [0.1, 0.2, 0.0],  # 勝った？\n",
    "            [0.0, 1.3, 0.1] ] # 悲しい？\n",
    "\n",
    "# シーズン４試合の足指の数の平均\n",
    "toes  = [8.5, 9.5, 9.9, 9.0]\n",
    "# シーズン４試合の勝率\n",
    "wlrec = [0.65,0.8, 0.8, 0.9]\n",
    "# シーズン４試合のファンの数\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "# シーズン４試合のけが度\n",
    "hurt  = [0.1, 0.0, 0.0, 0.1]\n",
    "# シーズン４試合の勝ち負け\n",
    "win   = [  1,   1,   0,   1]\n",
    "# シーズン４試合の悲しみ度\n",
    "sad   = [0.1, 0.0, 0.1, 0.2]\n",
    "# アルファの初期化\n",
    "alpha = 0.01\n",
    "# 入力データの設定（シーズン第１試合の [足指の数の平均値, 勝率, ファンの数]\n",
    "input = [toes[0], wlrec[0], nfans[0]]\n",
    "# シーズン第１試合の結果の設定（[けが度, 勝ち負け, 悲しみ度]\n",
    "truth  = [hurt[0], win[0], sad[0]]\n",
    "\n",
    "# 勾配降下法による学習\n",
    "# 予測値を求める\n",
    "\n",
    "# 学習する\n",
    "\n",
    "\n",
    "# 予測値を表示\n",
    "\n",
    "print('更新された重み')\n",
    "# 更新された重み行列を表示する（ループ）\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題２\n",
    "### ▶ 問題１のプログラムにおいて、学習を１０回実施するプログラムを下記の未完成リストのコメントに従って実装してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👇未完成リスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習 1 回目\n",
      "予測値 = [0.555, 0.9800000000000001, 0.9650000000000001]\n",
      "重み行列 = \n",
      "0.061325 : 0.0970425 : -0.30546\n",
      "0.1017 : 0.20013 : 0.00023999999999999887\n",
      "-0.07352500000000001 : 1.2943775 : 0.08962\n",
      "\n",
      "学習 2 回目\n",
      "予測値 = [0.217788125, 0.9948224999999999, 0.32392687499999984]\n",
      "重み行列 = \n",
      "0.051313009374999996 : 0.0962768771875 : -0.3068734575\n",
      "0.1021400875 : 0.20016365375 : 0.0003021299999999995\n",
      "-0.092558784375 : 1.2929219753124999 : 0.0869328775\n",
      "\n",
      "学習 3 回目\n",
      "予測値 = [0.13049240085937502, 0.9986596746875, 0.15796906976562497]\n",
      "重み行列 = \n",
      "0.04872115530195312 : 0.09607867658191406 : -0.3072393663103125\n",
      "0.1022540151515625 : 0.20017236586453124 : 0.00031821390374999885\n",
      "-0.09748615530507812 : 1.2925451763590232 : 0.0862372486628125\n",
      "\n",
      "学習 4 回目\n",
      "予測値 = [0.10789372027247063, 0.9996530232847265, 0.11500674293557611]\n",
      "重み行列 = \n",
      "0.04805018907879312 : 0.096027367400143 : -0.30733409095358216\n",
      "0.10228350817236075 : 0.20017462121318053 : 0.0003223776243332809\n",
      "-0.09876172845460209 : 1.2924476325299419 : 0.0860571677475856\n",
      "\n",
      "学習 5 回目\n",
      "予測値 = [0.10204348683553588, 0.9999101764028336, 0.10388487057744723]\n",
      "重み行列 = \n",
      "0.04787649269777257 : 0.09601408473571202 : -0.3073586127956086\n",
      "0.10229114317811988 : 0.2001752050665621 : 0.00032345550749927725\n",
      "-0.0990919424536851 : 1.2924223808711885 : 0.08601054930065623\n",
      "\n",
      "学習 6 回目\n",
      "予測値 = [0.10052900765454936, 0.9999767469162835, 0.10100569587073659]\n",
      "重み行列 = \n",
      "0.04783152704713587 : 0.09601064618595745 : -0.3073649608874632\n",
      "0.10229311969023579 : 0.20017535621160626 : 0.00032373454450387564\n",
      "-0.09917742660269771 : 1.2924158438480287 : 0.08599848095020739\n",
      "\n",
      "学習 7 回目\n",
      "予測値 = [0.10013694685657143, 0.9999939803579528, 0.10026034951853695]\n",
      "重み行列 = \n",
      "0.0478198865643273 : 0.09600975603138974 : -0.30736660424974205\n",
      "0.10229363135980979 : 0.20017539533927955 : 0.0003238067802084416\n",
      "-0.09919955631177335 : 1.2924141515761582 : 0.08599535675598495\n",
      "\n",
      "学習 8 回目\n",
      "予測値 = [0.10003545211749498, 0.999998441665165, 0.10006739798161135]\n",
      "重み行列 = \n",
      "0.04781687313434023 : 0.09600952559262602 : -0.307367029675152\n",
      "0.10229376381827077 : 0.20017540546845597 : 0.000323825480226461\n",
      "-0.09920528514021032 : 1.2924137134892777 : 0.08599454798020562\n",
      "\n",
      "学習 9 回目\n",
      "予測値 = [0.10000917766691647, 0.9999995965860696, 0.10001744765248952]\n",
      "重み行列 = \n",
      "0.04781609303265233 : 0.09600946593779106 : -0.307367139807155\n",
      "0.10229379810845485 : 0.20017540809064652 : 0.00032383032119362546\n",
      "-0.09920676819067192 : 1.2924136000795365 : 0.08599433860837574\n",
      "\n",
      "学習 10 回目\n",
      "予測値 = [0.10000237586852295, 0.9999998955662187, 0.10000451676103836]\n",
      "重み行列 = \n",
      "0.04781589108382788 : 0.09600945049464565 : -0.3073671683175773\n",
      "0.10229380698532625 : 0.2001754087694661 : 0.0003238315743990009\n",
      "-0.09920715211536019 : 1.2924135707205897 : 0.08599428440724328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NumPyのインポート、別名 np\n",
    "import numpy as np\n",
    "\n",
    "# 加重和（内積）を求める関数 w_sum の定義\n",
    "def w_sum(a, b):\n",
    "    # ２つの引数のリストの長さが等しいとき以下を実行する\n",
    "    assert(len(a) == len(b))\n",
    "    # 加重和の初期化\n",
    "    output = 0\n",
    "    # 加重和を求める\n",
    "    # 引数のリストの長さ分繰り返す\n",
    "    for i in range(len(a)):\n",
    "        # リストの要素同士を掛けて合計を求める\n",
    "        output += (a[i] * b[i])\n",
    "    # 加重和を返す\n",
    "    return output\n",
    "\n",
    "# ベクトルと行列のかけ算を求める関数 vect_mat_mul の定義\n",
    "\n",
    "    # ベクトルと行列の行リストの長さが等しいとき以下を実行する\n",
    "    \n",
    "    # 加重和リストの初期化\n",
    "    \n",
    "    # ベクトルの長さ（＝行列の行リストの長さ）分繰り返す\n",
    "    \n",
    "        # ベクトルの行列の各行との加重和を求める\n",
    "        \n",
    "    # 加重和のリストを返す\n",
    "    \n",
    "\n",
    "# ２つのリストの要素間を総なめして要素ごとのかけ算をして\n",
    "# その結果を行列に格納する関数 outer_prod の定義\n",
    "def outer_prod(a, b):\n",
    "    # a 行 b 列のゼロ行列を生成する\n",
    "    out = np.zeros((len(a), len(b)))\n",
    "    # a 行 b 列の行列にリスト a とリスト b の\n",
    "    # 要素を総なめしたかけ算を行い、行列に格納する\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(b)):\n",
    "            out[i][j] = a[i] * b[j]\n",
    "    # 要素間のかけ算の結果を保存した行列を返す\n",
    "    return out\n",
    "\n",
    "# 予測値を求める関数 nuural_network の定義\n",
    "def neural_network(input, weights):\n",
    "    # ベクトルと行列の加重和を求める\n",
    "    pred = vect_mat_mul(input, weights)\n",
    "    # 予測値のリストを返す\n",
    "    return pred\n",
    "\n",
    "# 学習関数 grad_descent_learn(input, truth, pred, weights, alpha) の定義\n",
    "'''\n",
    "関数名：grad_descent_learn\n",
    "引数：\n",
    "    input：入力値リスト\n",
    "    truth：目的値リスト\n",
    "    pred：予測値リスト\n",
    "    weights：重みリスト\n",
    "    alpha：重み再微調整値\n",
    "処理：勾配降下法に基づき重みを修正する\n",
    "戻り値：修正された重みリスト\n",
    "'''\n",
    "\n",
    "    # デルタの初期化\n",
    "    \n",
    "    # 予測値の数分繰り返す\n",
    "    \n",
    "        # デルタを求める\n",
    "        \n",
    "    # 重みの微調整量を求め行列に格納する\n",
    "    \n",
    "    # 重み行列を更新する（２重ループ）\n",
    "    \n",
    "    \n",
    "\n",
    "    # 重み行列を返す\n",
    "    \n",
    "\n",
    "# 予測値と更新された重みを表示する関数 disp_lear の定義\n",
    "'''\n",
    "関数名：disp_learn\n",
    "引数：\n",
    "    pred = 予測値リスト\n",
    "    weights = 重み行列\n",
    "処理：予測値と重みを表示する。ただし、重みは小数点８桁\n",
    "戻り値：なし\n",
    "'''\n",
    "\n",
    "    # 予測値を表示\n",
    "    \n",
    "    \n",
    "    # 更新された重み行列を表示する（ループ）\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 重みの初期化\n",
    "            #toes %win #fans\n",
    "weights = [ [0.1, 0.1, -0.3], # けが？\n",
    "            [0.1, 0.2, 0.0],  # 勝った？\n",
    "            [0.0, 1.3, 0.1] ] # 悲しい？\n",
    "\n",
    "# シーズン４試合の足指の数の平均\n",
    "toes  = [8.5, 9.5, 9.9, 9.0]\n",
    "# シーズン４試合の勝率\n",
    "wlrec = [0.65,0.8, 0.8, 0.9]\n",
    "# シーズン４試合のファンの数\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "# シーズン４試合のけが度\n",
    "hurt  = [0.1, 0.0, 0.0, 0.1]\n",
    "# シーズン４試合の勝ち負け\n",
    "win   = [  1,   1,   0,   1]\n",
    "# シーズン４試合の悲しみ度\n",
    "sad   = [0.1, 0.0, 0.1, 0.2]\n",
    "# アルファの初期化\n",
    "alpha = 0.01\n",
    "# 入力データの設定（シーズン第１試合の [足指の数の平均値, 勝率, ファンの数]\n",
    "input = [toes[0], wlrec[0], nfans[0]]\n",
    "# シーズン第１試合の結果の設定（[けが度, 勝ち負け, 悲しみ度]\n",
    "truth  = [hurt[0], win[0], sad[0]]\n",
    "\n",
    "# 勾配降下法による学習（１０回）\n",
    "\n",
    "    # 学習回数を表示\n",
    "    \n",
    "    # 予測値を求める\n",
    "    \n",
    "    # 学習する\n",
    "    \n",
    "    # 予測値と更新された重みを表示\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題３\n",
    "### ▶ 下図のネットワークにおいて、下記の実行結果のように１０回学習させるようにプログラムを実装してください\n",
    "### 注意）実行結果と全く同じでなくても構いません。学習が目的値に向かって進むのであればOKです。\n",
    "![](chap5_ex_2_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習 1 回目\n",
      "予測値 [1.16246 0.92272 1.44018]\n",
      "重み行列＝ [[0.77710821 0.62931013 0.5361909  0.4451262 ]\n",
      " [0.62137558 0.42508502 0.3865688  0.7123184 ]\n",
      " [0.7821648  0.54103616 0.7925847  0.7167946 ]]\n",
      "学習 2 回目\n",
      "予測値 [1.14171145 0.9325898  1.3839625 ]\n",
      "重み行列＝ [[0.77458575 0.61998552 0.52414543 0.44087486]\n",
      " [0.62257549 0.42952062 0.39229867 0.71434071]\n",
      " [0.77533026 0.51577142 0.75994789 0.70527573]]\n",
      "学習 3 回目\n",
      "予測値 [1.1236128  0.94119908 1.33492481]\n",
      "重み行列＝ [[0.77238544 0.6118518  0.51363834 0.43716647]\n",
      " [0.62362214 0.43338972 0.39729675 0.71610473]\n",
      " [0.7693686  0.49373337 0.73147928 0.69522798]]\n",
      "学習 4 回目\n",
      "予測値 [1.10782562 0.94870883 1.29214995]\n",
      "重み行列＝ [[0.77046614 0.60475687 0.50447316 0.4339317 ]\n",
      " [0.62453512 0.43676467 0.40165649 0.71764347]\n",
      " [0.76416833 0.4745099  0.70664653 0.68646348]]\n",
      "学習 5 回目\n",
      "予測値 [1.09405469 0.95525947 1.25483808]\n",
      "重み行列＝ [[0.76879197 0.59856807 0.49647851 0.43111006]\n",
      " [0.62533151 0.4397086  0.40545944 0.71898568]\n",
      " [0.75963222 0.45774156 0.6849853  0.67881834]]\n",
      "学習 6 回目\n",
      "予測値 [1.08204252 0.9609735  1.22229148]\n",
      "重み行列＝ [[0.76733161 0.59316967 0.4895049  0.42864879]\n",
      " [0.62602618 0.44227655 0.40877669 0.72015648]\n",
      " [0.75567543 0.44311478 0.66609052 0.6721496 ]]\n",
      "学習 7 回目\n",
      "予測値 [1.07156447 0.96595776 1.19390157]\n",
      "重み行列＝ [[0.76605777 0.58846073 0.48342192 0.42650185]\n",
      " [0.62663213 0.44451653 0.41167028 0.72117775]\n",
      " [0.75222398 0.43035606 0.64960889 0.66633255]]\n",
      "学習 8 回目\n",
      "予測値 [1.06242463 0.97030546 1.16913747]\n",
      "重み行列＝ [[0.76494661 0.58435319 0.47811582 0.42462911]\n",
      " [0.62716069 0.44647043 0.41419432 0.72206858]\n",
      " [0.74921333 0.41922681 0.6352322  0.66125842]]\n",
      "学習 9 回目\n",
      "予測値 [1.05445208 0.97409789 1.14753611]\n",
      "重み行列＝ [[0.76397736 0.58077024 0.4734874  0.42299555]\n",
      " [0.62762175 0.44817478 0.416396   0.72284565]\n",
      " [0.74658719 0.40951893 0.62269163 0.65683234]]\n",
      "学習 10 回目\n",
      "予測値 [1.04749774 0.97740597 1.12869357]\n",
      "重み行列＝ [[0.7631319  0.57764489 0.46945009 0.42157062]\n",
      " [0.62802392 0.44966147 0.41831649 0.72352347]\n",
      " [0.74429644 0.4010509  0.61175268 0.65297153]]\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "# NumPyのインポート、別名 np\n",
    "import numpy as np\n",
    "\n",
    "# 加重和（内積）を求める関数 w_sum の定義\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ベクトルと行列のかけ算を求める関数 vect_mat_mul の定義\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ２つのリストの要素間を総なめして要素ごとのかけ算をして\n",
    "# その結果を行列に格納する関数 outer_prod の定義\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 予測値を求める関数 nuural_network の定義\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 学習関数 grad_descent_learn(input, truth, pred, weights, alpha) の定義\n",
    "'''\n",
    "関数名：grad_descent_learn\n",
    "引数：\n",
    "    input：入力値リスト\n",
    "    truth：目的値リスト\n",
    "    pred：予測値リスト\n",
    "    weights：重みリスト\n",
    "    alpha：重み再微調整値\n",
    "処理：勾配降下法に基づき重みを修正する\n",
    "戻り値：修正された重みリスト\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 予測値と更新された重みを表示する関数 disp_lear の定義\n",
    "'''\n",
    "関数名：disp_learn\n",
    "引数：\n",
    "    pred = 予測値リスト\n",
    "    weights = 重み行列\n",
    "処理：予測値と重みを表示する。ただし、重みは小数点８桁\n",
    "戻り値：なし\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 入力値 [身長、体重、年収、血液型] の初期化\n",
    "inp=np.array([0.178,0.658,0.85,0.3])\n",
    "\n",
    "# 重み行列の初期化\n",
    "wei=np.array([[0.78,0.64,0.55,0.45],\n",
    "             [0.62,0.42,0.38,0.71],\n",
    "             [0.79,0.57,0.83,0.73]])\n",
    "\n",
    "\n",
    "\n",
    "# 目的値の初期化\n",
    "goal=np.array([1.0,1.0,1.0])\n",
    "\n",
    "# alpha の初期化\n",
    "alp=0.1\n",
    "\n",
    "# １０回学習する\n",
    "for i in range(10):\n",
    "    pred=np.dot(wei,inp)\n",
    "    err=pred-goal\n",
    "    DaM=np.outer(inp,err).T\n",
    "    wei-=(DaM*alp)\n",
    "    print(\"学習\",i+1,\"回目\\n予測値\",pred)\n",
    "    print(\"重み行列＝\",wei)\n",
    "'''\n",
    "なぜか手本が、重みの表示が12個必要なのに9つしか表自されていない\n",
    "考えられる限り、配列のインデックス同士を使っているので飛び出たインデックス分まで届かず\n",
    "正方行列とみなされ、4×3(入力値、誤差)の外積和から重みを調節しているのでなく、3×3の形で内積してそのままの値を使って調整しまっている？\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
